{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38cad3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b47d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Percentage Of Total Spend').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2312f681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+-------------+----------------+\n",
      "| id|cust_id|order_date|order_details|total_order_cost|\n",
      "+---+-------+----------+-------------+----------------+\n",
      "|  1|      3|2019-03-04|         Coat|             100|\n",
      "|  2|      3|2019-03-01|        Shoes|              80|\n",
      "|  3|      3|2019-03-07|        Skirt|              30|\n",
      "|  4|      7|2019-02-01|         Coat|              25|\n",
      "|  5|      7|2019-03-10|        Shoes|              80|\n",
      "|  6|     15|2019-02-01|        Boats|             100|\n",
      "|  7|     15|2019-01-11|       Shirts|              60|\n",
      "|  8|     15|2019-03-11|      Slipper|              20|\n",
      "|  9|     15|2019-03-01|        Jeans|              80|\n",
      "| 10|     15|2019-03-09|       Shirts|              50|\n",
      "| 11|      5|2019-02-01|        Shoes|              80|\n",
      "| 12|     12|2019-01-11|       Shirts|              60|\n",
      "| 13|     12|2019-03-11|      Slipper|              20|\n",
      "| 14|      4|2019-02-01|        Shoes|              80|\n",
      "| 15|      4|2019-01-11|       Shirts|              60|\n",
      "| 16|      3|2019-04-19|       Shirts|              50|\n",
      "| 17|      7|2019-04-19|         Suit|             150|\n",
      "| 18|     15|2019-04-19|        Skirt|              30|\n",
      "| 19|     15|2019-04-20|      Dresses|             200|\n",
      "| 20|     12|2019-01-11|         Coat|             125|\n",
      "+---+-------+----------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+----------+---------+-------------+--------------------+------------+\n",
      "| id|first_name|last_name|         city|             address|phone_number|\n",
      "+---+----------+---------+-------------+--------------------+------------+\n",
      "|  8|      John|   Joseph|San Francisco|                null|928-386-8164|\n",
      "|  7|      Jill|  Michael|       Austin|                null|813-297-0692|\n",
      "|  4|   William|   Daniel|       Denver|                null|813-368-1200|\n",
      "|  5|     Henry|  Jackson|        Miami|                null|808-601-7513|\n",
      "| 13|      Emma|    Isaac|        Miami|                null|808-690-5201|\n",
      "| 14|      Liam|   Samuel|        Miami|                null|808-555-5201|\n",
      "| 15|       Mia|     Owen|        Miami|                null|808-640-5201|\n",
      "|  1|      Mark|   Thomas|      Arizona|  4476 Parkway Drive|602-993-5916|\n",
      "| 12|       Eva|    Lucas|      Arizona|     4379 Skips Lane|301-509-8805|\n",
      "|  6|      Jack|    Aiden|      Arizona|  4833 Coplin Avenue|480-303-1527|\n",
      "|  2|      Mona|   Adrian|  Los Angeles|     1958 Peck Court|714-409-9432|\n",
      "| 10|      Lili|   Oliver|  Los Angeles|  3832 Euclid Avenue|530-695-1180|\n",
      "|  3|    Farida|   Joseph|San Francisco|3153 Rhapsody Street|813-368-1200|\n",
      "|  9|    Justin|Alexander|       Denver|4470 McKinley Avenue|970-433-7589|\n",
      "| 11|     Frank|    Jacob|        Miami|  1299 Randall Drive|        null|\n",
      "+---+----------+---------+-------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_order_input = spark.read.options(header='True', InferSchema='True').csv('orders_amazon.csv')\n",
    "df_customer_input = spark.read.options(header='True', InferSchema='True').csv('customer.csv')\n",
    "df_order_input.show()\n",
    "df_customer_input.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99e0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_order_input.join(df_customer_input, df_order_input.cust_id == df_customer_input.id, 'left').selectExpr('cust_id','order_date','total_order_cost','first_name','last_name')\n",
    "#df_combined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ed3255b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+---------------+\n",
      "|cust_id|total_order_cost|percetage_spend|\n",
      "+-------+----------------+---------------+\n",
      "|      3|              50|           50.0|\n",
      "|      3|             100|          100.0|\n",
      "|      3|              30|           30.0|\n",
      "|      3|              80|           80.0|\n",
      "|      4|              80|           80.0|\n",
      "|      4|              60|           60.0|\n",
      "|      5|              80|           80.0|\n",
      "|      7|              30|           30.0|\n",
      "|      7|              25|           25.0|\n",
      "|      7|              80|           80.0|\n",
      "|      7|             150|          150.0|\n",
      "|      7|              50|           50.0|\n",
      "|      7|             125|          125.0|\n",
      "|     12|              60|           60.0|\n",
      "|     12|              20|           20.0|\n",
      "|     12|             125|          125.0|\n",
      "|     15|              30|           30.0|\n",
      "|     15|             200|          200.0|\n",
      "|     15|              50|           50.0|\n",
      "|     15|             100|          100.0|\n",
      "|     15|              60|           60.0|\n",
      "|     15|              20|           20.0|\n",
      "|     15|              80|           80.0|\n",
      "+-------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_combined.createOrReplaceTempView(\"fb\")\n",
    "df_most_flagged_video = spark.sql(\"select cust_id,total_order_cost,avg(total_order_cost) as percetage_spend from fb group by cust_id,total_order_cost order by cust_id\")\n",
    "df_most_flagged_video.show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85584c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
