{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4325d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import max,countDistinct,col,regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2e7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local').appName('Walmart Stock').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac71a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+\n",
      "|seller_id|seller_name|daily_target|\n",
      "+---------+-----------+------------+\n",
      "|        0|   seller_0|     2500000|\n",
      "|        1|   seller_1|     1375559|\n",
      "|        2|   seller_2|      205349|\n",
      "|        3|   seller_3|       71546|\n",
      "|        4|   seller_4|     1315668|\n",
      "+---------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_order_input = spark.read.options(header ='True', InferSchema='True').csv('sales.csv')\n",
    "df_order_input = df_order_input.withColumnRenamed(\"product_id\",\"ordered_product_id\")\n",
    "df_seller_input = spark.read.options(header ='True', InferSchema='True').csv('sellers.csv')\n",
    "df_product_input = spark.read.options(header ='True', InferSchema='True').csv('products.csv')\n",
    "#df_order_input.show(5)\n",
    "#df_product_input.show(5)\n",
    "#df_seller_input.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0319746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order:20000040 Product:75000000 Seller:10\n"
     ]
    }
   ],
   "source": [
    "##Find out how many orders, how many products and how many sellers are in the data.\n",
    "print ('Order:' +str(df_order_input.count()),'Product:'+str(df_product_input.count()),'Seller:'+str(df_seller_input.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325a6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##How many products have been sold at least once? Which is the product contained in more orders?\n",
    "df_order_input.createOrReplaceTempView(\"order\")\n",
    "df_multiple_order= spark.sql(\"select ordered_product_id from(select ordered_product_id,count(*) as count from order group by ordered_product_id having count(*) > 1 )\")\n",
    "df_max_order= spark.sql(\"select max(count) as max_product_ordered from (select ordered_product_id,count(*) as count from order group by ordered_product_id having count(*) > 1 )\")\n",
    "#df_multiple_order.show()\n",
    "#df_max_order.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d30a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      date| count|\n",
      "+----------+------+\n",
      "|2020-07-03|100224|\n",
      "|2020-07-07| 99453|\n",
      "|2020-07-01| 99755|\n",
      "|2020-07-08|100048|\n",
      "|2020-07-04|100294|\n",
      "|2020-07-10|100218|\n",
      "|2020-07-09| 99801|\n",
      "|2020-07-06| 99869|\n",
      "|2020-07-02| 99768|\n",
      "|2020-07-05| 99991|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##how many distinct products have been sold in each date\n",
    "df_selected_col = df_order_input.select('date','ordered_product_id').distinct()\n",
    "df_each_day = df_selected_col.groupBy('date').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae15406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(revenue)|\n",
      "+------------------+\n",
      "|1245.9236386027228|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##What is the average revenue of the orders?\n",
    "df_order_product = df_order_input.join(df_product_input, df_order_input.ordered_product_id == df_product_input.product_id, 'inner').selectExpr('date','product_id','num_pieces_sold','price')\n",
    "df_revenue = df_order_product.withColumn('revenue', col(\"price\") * col(\"num_pieces_sold\"))\n",
    "df_revenue = df_revenue.agg({\"revenue\": \"avg\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d8fc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "##“Who are the second most selling and the least selling persons (sellers) for each product? \n",
    "##Who are those for the product with product_id = 0”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "034985b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##If a product has been sold by only one seller\n",
    "df_selected_col = df_order_input.select('order_id','seller_id','ordered_product_id','num_pieces_sold')\n",
    "df_selected_col.createOrReplaceTempView(\"order\")\n",
    "df_single_seller= spark.sql(\"select num_pieces_sold,ordered_product_id,count(distinct seller_id) as count FROM order group by ordered_product_id,num_pieces_sold having count = 1 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec496678",
   "metadata": {},
   "outputs": [],
   "source": [
    "##If a product has been sold by more than one seller, but all of them sold the same quantity\n",
    "df_selected_col = df_order_input.select('order_id','seller_id','ordered_product_id','num_pieces_sold')\n",
    "df_selected_col.createOrReplaceTempView(\"order\")\n",
    "df_multiple_seller= spark.sql(\"select num_pieces_sold,ordered_product_id,count(distinct seller_id) as count FROM order group by ordered_product_id,num_pieces_sold having count > 1 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "701941a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+---------+----------+---------------+--------------------+\n",
      "|order_id|ordered_product_id|seller_id|      date|num_pieces_sold|       bill_raw_text|\n",
      "+--------+------------------+---------+----------+---------------+--------------------+\n",
      "|  482779|          24185211|        3|2020-07-02|             37|yisdoasufImlvwzxv...|\n",
      "+--------+------------------+---------+----------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_order_input.filter('ordered_product_id == 24185211').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35f23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merging both scenario and creating one df\n",
    "df_merged = df_single_seller.union(df_multiple_seller)\n",
    "df_merged = df_merged.withColumnRenamed(\"ordered_product_id\",\"prod_id\")\n",
    "df_merged = df_merged.withColumnRenamed(\"num_pieces_sold\",\"num_piece_sold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50bec382",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = [df_merged.prod_id == df_order_input.ordered_product_id, df_merged.num_piece_sold == df_order_input.num_pieces_sold]\n",
    "df_combined = df_order_input.join(df_merged, cond , 'inner').orderBy('seller_id').selectExpr('order_id','prod_id','seller_id','num_piece_sold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9fede16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## take the sum of pieces sold based on seller_id \n",
    "df_combined.createOrReplaceTempView(\"order_output\")\n",
    "df= spark.sql(\"select prod_id,seller_id,sum(num_piece_sold) as count from order_output where prod_id ='0' group by seller_id,prod_id order by seller_id,prod_id asc \")\n",
    "#df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0130fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using rank function to find out least and second most seller_id and merging both df\n",
    "df.createOrReplaceTempView(\"masterorder\")\n",
    "df_second_most_seller= spark.sql(\"select prod_id,seller_id,count,rn from \"+ \" (select   prod_id,seller_id,count, RANK() OVER (PARTITION BY prod_id ORDER BY count DESC) as rn \" +\" FROM masterorder) tmp where rn =2 \")\n",
    "df_least_most_seller= spark.sql(\"select prod_id,seller_id,count,rn from \"+ \" (select   prod_id,seller_id,count, RANK() OVER (PARTITION BY prod_id ORDER BY count ASC) as rn \" +\" FROM masterorder) tmp where rn =1  \")\n",
    "df_final_output = df_second_most_seller.union(df_least_most_seller)\n",
    "#df_final_output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cd1a3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------+\n",
      "|prod_id|               rn|seller_name|\n",
      "+-------+-----------------+-----------+\n",
      "|      0|Least-Most Seller|   seller_0|\n",
      "+-------+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## finding out the seller name\n",
    "df_final_opt = df_final_output.join(df_seller_input, df_final_output.seller_id == df_seller_input.seller_id, 'inner')\n",
    "df_final_opt.withColumn('rn', regexp_replace('rn', '2', 'Second-Most Seller')).withColumn('rn', regexp_replace('rn', '1', 'Least-Most Seller')).selectExpr('prod_id','rn','seller_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967da23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
